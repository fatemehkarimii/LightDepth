{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"871353ff762540f4810fb203168ae25d":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["tf_implementation/ckpts/ko_s10_ilr-7_dr8_DNet169_F_20210611-113315","tf_implementation/ckpts/ko_s10_ilr-4_dr8_DNet169_F_20210613-111645","tf_implementation/ckpts/ko_b8_s10_ilr-4_dr8_DNet169_F_20210613-112635","tf_implementation/ckpts/lr-4_f_20210617-205205","tf_implementation/ckpts/ko_b8_gt_ilr-4_dr8_dnet169_F_20210618-074730","tf_implementation/ckpts/LR-4,BS16,TRUE_20210618-195754","tf_implementation/ckpts/LR-4,GT,BS16,TRUE_20210620-150607","tf_implementation/ckpts/LR-4,GT,BS8,TRUE_20210620-161919","tf_implementation/ckpts/LR-4_S11_agm:T_20210626-135329","tf_implementation/ckpts/LR-4_S14_agm:T_20210626-135423","tf_implementation/ckpts/LR-4_S11_agm:T_withFilip_20210703-084625","tf_implementation/ckpts/GT_20210704-111657","tf_implementation/ckpts/LR-4_*2_20210712-100733","tf_implementation/ckpts/TEST-efficientnet5_20210718-134951","tf_implementation/ckpts/11eficientNet_20210718-165149","tf_implementation/ckpts/bts_11S_20210801-141257","tf_implementation/ckpts/31strategy_20211026-150004"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Version","description_tooltip":null,"disabled":false,"index":9,"layout":"IPY_MODEL_6287789b53cb43adbbbda1c372aa0abd","style":"IPY_MODEL_9567c8e6735340f0a532bf879b161fe4"}},"6287789b53cb43adbbbda1c372aa0abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9567c8e6735340f0a532bf879b161fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a74ef955a6f48f98d17835462d2f498":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Version Name","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_a3ac153d8f584ee1b27e1100385e78f4","placeholder":"​","style":"IPY_MODEL_5d014ee970034426ac5620b88be10e18","value":""}},"a3ac153d8f584ee1b27e1100385e78f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d014ee970034426ac5620b88be10e18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ba59fa4c1aa41509931be5346ac7ba2":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Create New Version","disabled":false,"icon":"","layout":"IPY_MODEL_65841fc88a1941209e1cce2a5d51f1a3","style":"IPY_MODEL_3483ed7be9284bcbbef59e3240cb7eec","tooltip":""}},"65841fc88a1941209e1cce2a5d51f1a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3483ed7be9284bcbbef59e3240cb7eec":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bafx3h74GiZ4","executionInfo":{"status":"ok","timestamp":1669167492200,"user_tz":-210,"elapsed":26747,"user":{"displayName":"Fatemeh Karimi","userId":"10033556401034287336"}},"outputId":"07629d19-f7fb-4620-8459-eb80ac1cbec8","cellView":"form"},"source":["#@title mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"fJG50933HNLi","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"ok","timestamp":1669167460766,"user_tz":-210,"elapsed":8410,"user":{"displayName":"Fatemeh Karimi","userId":"10033556401034287336"}},"outputId":"44b09b3f-fa87-42cc-ef77-edb79583eeed"},"source":["#@title imports\n","%%capture\n","%cd /content/drive/MyDrive/DepthEstimation/\n"," \n","!pip install tensorflow-addons\n","# !pip install segmentation-models\n"," \n","%load_ext autoreload\n","%autoreload 2\n","%load_ext tensorboard\n"," \n","import matplotlib.pyplot as plt\n","import os\n","from glob import glob \n","import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","import json\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import ipywidgets as widgets\n","from tqdm.notebook import tqdm\n","import IPython\n","\n","# internal codes\n","from tf_implementation.scripts.dataloaders import OrdinaryDataloader\n","from tf_implementation.scripts.models.ordinary_unet import OrdinaryUNet\n","from tf_implementation.scripts.models.efficient_unet import EfficientUNet\n"," \n","from tf_implementation.scripts.utils import good\n","from tf_implementation.scripts.utils import update_train_filenames_file\n"," \n","from tf_implementation.config import Config"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-49da45fa082a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# internal codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinaryDataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinary_unet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinaryUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficient_unet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_implementation'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146,"referenced_widgets":["871353ff762540f4810fb203168ae25d","6287789b53cb43adbbbda1c372aa0abd","9567c8e6735340f0a532bf879b161fe4","9a74ef955a6f48f98d17835462d2f498","a3ac153d8f584ee1b27e1100385e78f4","5d014ee970034426ac5620b88be10e18","3ba59fa4c1aa41509931be5346ac7ba2","65841fc88a1941209e1cce2a5d51f1a3","3483ed7be9284bcbbef59e3240cb7eec"]},"id":"gORedhPrHmaZ","executionInfo":{"status":"ok","timestamp":1647877766591,"user_tz":-210,"elapsed":637,"user":{"displayName":"Fatemeh Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10033556401034287336"}},"outputId":"543aeec7-53ca-4d17-b37c-bbb19f1d19e4"},"source":["#@title version control\n","%cd /content/drive/MyDrive/DepthEstimation/\n","def create_version(_):\n","    if version_name_widget.value == '':\n","        print('please set a name for this version')\n","        return\n","    config.create_version(version_name_widget.value)\n"," \n","version_name_widget = widgets.Text(description='Version Name',\n","                                   value=None)\n","version_widget = widgets.Dropdown(options=glob('tf_implementation/ckpts/*'),\n","                                  description='Version',\n","                                  value=None)\n","create_version_widget = widgets.Button(description='Create New Version')\n"," \n","base_setting = json.load(open(('tf_implementation/settings/setting_kitti_base.json'),\n","                         'r'))\n"," \n","config = Config(base_setting)\n"," \n","create_version_widget.on_click(create_version)\n","version_widget.observe(lambda x:config.load_version(x['new']),\n","                       names='value')\n","display(version_widget,version_name_widget,create_version_widget)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1wKHm-ijQtTFzHuPvQrblssopTQbWyzus/DepthEstimation\n"]},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Version', options=('tf_implementation/ckpts/ko_s10_ilr-7_dr8_DNet169_F_20210611-113315',…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"871353ff762540f4810fb203168ae25d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Text(value='', description='Version Name')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a74ef955a6f48f98d17835462d2f498"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(description='Create New Version', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ba59fa4c1aa41509931be5346ac7ba2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["version set to tf_implementation/ckpts/LR-4_S14_agm:T_20210626-135423\n"]}]},{"cell_type":"code","metadata":{"id":"HtU7TdyBH3Dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643796481393,"user_tz":-210,"elapsed":113777,"user":{"displayName":"Fateme Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00001635288917064784"}},"outputId":"1e904e29-d62e-470e-d430-91426be600e8"},"source":["#@title training\n","%cd /content/drive/MyDrive/DepthEstimation/\n","\n","early_stopping_counter = 0\n","\n","train_dataloader = OrdinaryDataloader(config)\n","test_dataloader = OrdinaryDataloader(config,\n","                                     is_training=False)\n","\n","train_summary_writer = tf.summary.create_file_writer(config.train_log_dir)\n","test_summary_writer = tf.summary.create_file_writer(config.test_log_dir)\n","\n","dataloader_iter = iter(train_dataloader.loader)\n","if config.encoder.startswith('DenseNet'):\n","    ounet = OrdinaryUNet(config)\n","else:\n","    ounet = EfficientUNet(config)\n","\n","ckpt = tf.train.Checkpoint(step=tf.Variable(0),\n","                           train_loss=tf.Variable(0.0),\n","                           test_loss=tf.Variable(0.0),\n","                           strategy=tf.Variable(0),\n","                           optimizer = ounet.optimizer,\n","                           model=ounet.model)\n","\n","last_manager = tf.train.CheckpointManager(ckpt,\n","                                          directory=config.last_ckpt_path,\n","                                          max_to_keep=config.max_to_keep_last_ckpt)\n","best_manager = tf.train.CheckpointManager(ckpt,\n","                                          directory=config.best_ckpt_path,\n","                                          max_to_keep=config.max_to_keep_best_ckpt)\n","\n","if best_manager.latest_checkpoint:\n","    ckpt.restore(best_manager.latest_checkpoint)\n","    best_test_loss=ckpt.test_loss.numpy()\n","    print(f'best test loss set to {best_test_loss}')\n","else:\n","    print('best test loss set to inf')\n","    best_test_loss = np.inf\n","\n","if last_manager.latest_checkpoint:\n","    ckpt.restore(last_manager.latest_checkpoint)\n","    step = ckpt.step.numpy()\n","    best_train_loss=ckpt.train_loss.numpy()\n","    train_dataloader.current_strategy = ckpt.strategy.numpy()\n","    print(f'restored from {last_manager.latest_checkpoint} starting from [{step-1}][{train_dataloader.current_strategy}]')\n","else:\n","    print('Initializing from scratch.')\n","    best_train_loss = np.inf\n","    step = 0\n","\n","while step < config.max_steps:\n","    image, depth_gt = dataloader_iter.get_next()\n","    loss,amax,amin = ounet.train_step(image, depth_gt)\n","\n","    with train_summary_writer.as_default():\n","        tf.summary.scalar('loss', loss , step=step)\n","        tf.summary.scalar('amax est', amax.numpy() , step=step)\n","        tf.summary.scalar('amin est', amin.numpy() , step=step)\n","        tf.summary.scalar('amax gt', np.amax(depth_gt) , step=step)\n","        tf.summary.scalar('amin gt', np.amin(depth_gt) , step=step)\n","        train_summary_writer.flush()\n","\n","    if step > config.num_warmup_steps:\n","        if not step%config.num_steps_per_train_checkpoint and\\\n","                config.save_checkpoints:\n","            ckpt.step.assign(step)\n","            ckpt.train_loss.assign(loss)\n","            ckpt.strategy.assign(train_dataloader.current_strategy)\n","            last_manager.save()\n","            print(f'Train checkpoint-[{step}][{train_dataloader.current_strategy}]')\n","\n","        if  loss < config.early_stopping_thresh*best_train_loss:\n","            early_stopping_counter = 0\n","            best_train_loss = loss\n","        elif train_dataloader.current_strategy < train_dataloader.num_strategies-1:\n","            early_stopping_counter += 1\n","            if early_stopping_counter > train_dataloader.early_stopping_patience:\n","                train_dataloader.current_strategy += 1\n","                early_stopping_counter = 0\n","\n","    if step > config.num_warmup_steps and\\\n","                not step%config.num_steps_per_test_checkpoint and\\\n","                config.save_checkpoints:\n","        \n","        metrics = dict(a1=[], a2=[], a3=[],\n","                    abs_rel=[], rmse=[], log_10=[],\n","                    rmse_log=[], silog=[], sq_rel=[])\n","        test_loss = []\n","        for test_image, test_depth_gt in tqdm(test_dataloader.loader):\n","            temp_metrics = ounet.compute_metrics(test_image,\n","                                             test_depth_gt)\n","            loss,depth_est = ounet.test_step(test_image,\n","                                              test_depth_gt)\n","            test_loss.append(loss.numpy())\n","            [metrics[k].append(v) for k,v in temp_metrics.items()]\n","        metrics = {k:np.mean(v) for k,v in metrics.items()}\n","        metrics['loss'] = np.mean(test_loss)\n","        print('metrics',\n","              ', '.join(f'{k} = {v}' for k,v in metrics.items()))\n","        with test_summary_writer.as_default():\n","            tf.summary.image('depth_est_sample',\n","                             depth_est,\n","                             step=step)\n","            tf.summary.image('gt_sample',\n","                             test_depth_gt,\n","                             step=step)\n","            tf.summary.image('input_sample',\n","                             test_image,\n","                             step=step)\n","            for name, value in metrics.items():\n","                tf.summary.scalar(name, value, step=step)\n","            test_summary_writer.flush()\n","\n","        if  metrics['loss'] < best_test_loss:\n","            best_test_loss = metrics['loss']\n","            ckpt.step.assign(step)\n","            ckpt.test_loss.assign(best_test_loss)\n","            ckpt.strategy.assign(train_dataloader.current_strategy)\n","            ckpt.save_counter.assign_sub(1)\n","            best_manager.save()\n","            print(f'Test checkpoint-[{step}][{train_dataloader.current_strategy}]')\n","\n","    print(f'train\\t[{step}][{train_dataloader.current_strategy}][{early_stopping_counter}=<{train_dataloader.early_stopping_patience}]\\tloss\\t{loss:1.5f}')\n","    step+=1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DepthEstimation\n","Cropping training images as kitti benchmark images\n","Rotating training images\n","Cropping training images as kitti benchmark images\n","best test loss set to 0.011205586604773998\n","Initializing from scratch.\n","image.shape (16, 256, 512, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"yzIkUoCORnW8"},"source":["# !echo $(ps -e | grep 'tensorboard' | awk '{print $1}')\n","# !kill $(ps -e | grep 'tensorboard' | awk '{print $1}')\n","%tensorboard --logdir tf_implementation/logs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZAkljGughJd","cellView":"form"},"source":["#@title Visualize output\n","test = False #@param {type:\"boolean\"}\n","# edit config\n","config.train_batch_size = 1\n","config.do_flip=False\n","config.do_rotate=False\n","config.garg_crop=False\n","config.do_kb_crop=False\n","config.do_augment=False\n","\n","\n","if test:\n","    temp_dataloader = OrdinaryDataloader(config,\n","                                        is_training=False,\n","                                         debug=True)\n","else:\n","    temp_dataloader = OrdinaryDataloader(config,\n","                                        is_training=True,\n","                                         debug=True)\n","    \n","ounet=OrdinaryUNet(config)\n","\n","int_text = widgets.IntText(\n","    description='Index')\n","\n","ckpt = tf.train.Checkpoint(step=tf.Variable(0),\n","                           train_loss=tf.Variable(0.0),\n","                           test_loss=tf.Variable(0.0),\n","                           strategy=tf.Variable(0),\n","                           optimizer = ounet.optimizer,\n","                           model=ounet.model)\n","\n","best_manager = tf.train.CheckpointManager(ckpt,\n","                                          directory=config.best_ckpt_path,\n","                                          max_to_keep=config.max_to_keep_best_ckpt)\n","\n","if not best_manager.latest_checkpoint:\n","    raise FileNotFoundError('No test checkpoint found!')\n","\n","ckpt.restore(best_manager.latest_checkpoint)\n","\n","@widgets.interact(image_id=int_text)\n","def render(image_id):\n","    IPython.display.clear_output()\n","    print(f'PLASE WAIT PROCESSING IMG {image_id}')\n","    for idx,(test_image, test_depth_gt) in enumerate(temp_dataloader.loader):\n","        if image_id > idx:\n","            continue\n","        break\n","    loss,depth_est = ounet.test_step(test_image,\n","                                     test_depth_gt)\n","    fig, axes = plt.subplots(3,1,figsize=(28,23))\n","    axes[0].imshow(tf.squeeze(depth_est).numpy())\n","    axes[1].imshow(good(tf.squeeze(test_image).numpy()))\n","    axes[2].imshow(tf.squeeze(test_depth_gt).numpy())\n","    plt.savefig(f'pdf_output/output_{image_id}.pdf',dpi=400)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rnhvzMtdjmK","cellView":"form"},"source":["#@title visualize curriculum\n","base_setting = json.load(open(('tf_implementation/settings/setting_kitti_base.json'),\n","                         'r'))\n","curriculum_setting = json.load(open(('tf_implementation/settings/31strategy_20211026-150004.json'),\n","                         'r'))\n","base_setting.update(curriculum_setting)\n","\n","config = Config(base_setting)\n","\n","train_dataloader = OrdinaryDataloader(config,\n","                                      debug=True)\n","int_text_curriculum = widgets.IntText(description='Index')\n","@widgets.interact(image_id=int_text_curriculum)\n","def render(image_id):\n","    depth_gts = []\n","    IPython.display.clear_output()\n","    for curr_stategy in range(len(train_dataloader.strategies)):\n","        train_dataloader.current_strategy = curr_stategy\n","        for idx,(train_image, train_depth_gt) in enumerate(train_dataloader.loader):\n","            if image_id > idx:\n","                continue\n","            break\n","        print(f'PLASE WAIT PROCESSING IMG {idx} STR {curr_stategy}')\n","        depth_gts.append(train_depth_gt)\n","    num_images= len(depth_gts)+1\n","    fig, axes = plt.subplots(num_images,1,figsize=(25,9*num_images))\n","    axes[0].imshow(good(tf.squeeze(train_image).numpy()))\n","    for i,gt in enumerate(depth_gts,1):\n","        axes[i].imshow(tf.squeeze(gt).numpy())\n","    #plt.figure()\n","    plt.savefig(f'pdf_output/input_{image_id}.pdf',dpi=400)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"pzF2w-0bTcbb"},"source":["#@title remove checkpoints & logs\n","command = \"list\" #@param [\"list\", \"remove\"]\n","address = \"ckpts\" #@param [\"logs\", \"ckpts\"]\n","if command == \"remove\":\n","    if address == 'logs':\n","        !rm -rf tf_implementation/logs/*\n","    else:\n","        !rm -rf tf_implementation/ckpts/*\n","else:\n","    !ls tf_implementation/ckpts/best_models/*\n","    !ls tf_implementation/ckpts/last_model/*\n","    !ls tf_implementation/logs/*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-TtVIz__VpI","cellView":"form"},"source":["#@title visualize curriculum histogram\n","base_setting = json.load(open(('tf_implementation/settings/setting_kitti_base.json'),\n","                         'r'))\n","curriculum_setting = json.load(open(('tf_implementation/settings/setting_test.json'),\n","                         'r'))\n","base_setting.update(curriculum_setting)\n","\n","config = Config(base_setting)\n","\n","train_dataloader = OrdinaryDataloader(config,\n","                                      debug=True)\n","int_text_curriculum = widgets.IntText(description='Index')\n","def hash_syllabus(syllabus):\n","    k0 = syllabus['pool_size'][0]\n","    k1 = syllabus['pool_size'][1]\n","    it = syllabus['iterations']\n","    return f'{it}x({k0},{k1})'\n","\n","@widgets.interact(image_id=int_text_curriculum)\n","def render(image_id):\n","    depth_gts = []\n","    IPython.display.clear_output()\n","    for curr_stategy in range(len(train_dataloader.strategies)):\n","        train_dataloader.current_strategy = curr_stategy\n","        for idx,(train_image, train_depth_gt) in enumerate(train_dataloader.loader):\n","            if image_id > idx:\n","                continue\n","            break\n","        print(f'PLASE WAIT PROCESSING IMG {idx} STR {curr_stategy}')\n","        depth_gts.append(train_depth_gt)\n","    num_images = len(depth_gts)+1\n","    # plt.imshow(tf.squeeze(depth_gts[5][0,:,:,:]).numpy())\n","    plt.figure(figsize=(8,5))\n","    df_dict = {'values':[],\n","               'syllabuses':[]}\n","    for i,gt in enumerate(depth_gts):\n","        gt = gt.numpy().flatten()\n","        gt = gt[gt>config.min_depth]\n","        df_dict['syllabuses']+=[hash_syllabus(train_dataloader.strategies[i])]*len(gt)\n","        df_dict['values'] += gt.tolist()\n","    df = pd.DataFrame(df_dict)\n","    sns.histplot(data=df,\n","                 x='values',\n","                 y='syllabuses',\n","                 bins=50)\n","    plt.grid()\n","    plt.savefig(f'pdf_output/input_hist_{image_id}.pdf',dpi=400)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnzEEyEuW_7_","cellView":"form"},"source":["#@title visualize curriculum histogram 2\n","base_setting = json.load(open(('tf_implementation/settings/setting_kitti_base.json'),\n","                         'r'))\n","curriculum_setting = json.load(open(('tf_implementation/settings/setting_test.json'),\n","                         'r'))\n","base_setting.update(curriculum_setting)\n","\n","config = Config(base_setting)\n","config.train_batch_size=32\n","train_dataloader = OrdinaryDataloader(config,\n","                                      debug=True)\n","def hash_syllabus(syllabus):\n","    k0 = syllabus['pool_size'][0]\n","    k1 = syllabus['pool_size'][1]\n","    it = syllabus['iterations']\n","    return f'{it}x({k0},{k1})'\n","int_text_curriculum = widgets.IntText(description='Index')\n","@widgets.interact(image_id=int_text_curriculum)\n","def render(image_id):\n","    depth_gts = []\n","    IPython.display.clear_output()\n","    for curr_stategy in range(len(train_dataloader.strategies)):\n","        train_dataloader.current_strategy = curr_stategy\n","        for idx,(train_image, train_depth_gt) in enumerate(train_dataloader.loader):\n","            if image_id > idx:\n","                continue\n","            break\n","        print(f'PLASE WAIT PROCESSING IMG {idx} STR {curr_stategy}')\n","        depth_gts.append(train_depth_gt)\n","    num_images = len(depth_gts)+1\n","    plt.figure(figsize=(8,3))\n","    df_dict = {'count':[],\n","               'syllabuses':[]}\n","    for i,gt in enumerate(depth_gts):\n","        gt = gt.numpy().flatten()\n","        df_dict['count'].append(len(gt[gt>config.min_depth])/config.train_batch_size)\n","        df_dict['syllabuses'].append(hash_syllabus(train_dataloader.strategies[i]))\n","    df = pd.DataFrame(df_dict)\n","    df['density'] = df['count']/(256*512)\n","    chart = sns.barplot(data=df,\n","                x='syllabuses',\n","                y='density',\n","                color=sns.palettes.color_palette('Blues')[3])\n","    chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')\n","    plt.grid()\n","    plt.savefig(f'pdf_output/input_hist2_{image_id}.pdf',\n","                dpi=400,\n","                bbox_inches ='tight')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TfLite"],"metadata":{"id":"ayHBJJwDLEdO"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/DepthEstimation/\n","\n","early_stopping_counter = 0\n","\n","if config.encoder.startswith('DenseNet'):\n","    ounet = OrdinaryUNet(config)\n","else:\n","    ounet = EfficientUNet(config)\n","\n","ckpt = tf.train.Checkpoint(step=tf.Variable(0),\n","                           train_loss=tf.Variable(0.0),\n","                           test_loss=tf.Variable(0.0),\n","                           strategy=tf.Variable(0),\n","                           optimizer = ounet.optimizer,\n","                           model=ounet.model)\n","\n","best_manager = tf.train.CheckpointManager(ckpt,\n","                                          directory=config.best_ckpt_path,\n","                                          max_to_keep=config.max_to_keep_best_ckpt)\n","\n","if best_manager.latest_checkpoint:\n","    ckpt.restore(best_manager.latest_checkpoint)\n","    best_test_loss=ckpt.test_loss.numpy()\n","    print(f'best test loss set to {best_test_loss}')\n","else:\n","    print('best test loss set to inf')\n","    best_test_loss = np.inf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzqGNPpGNimS","executionInfo":{"status":"ok","timestamp":1647878668624,"user_tz":-210,"elapsed":23336,"user":{"displayName":"Fatemeh Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10033556401034287336"}},"outputId":"b4a279bb-d202-4510-aea8-9af43fd78a1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1wKHm-ijQtTFzHuPvQrblssopTQbWyzus/DepthEstimation\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f39fe6aadd0> and <keras.layers.merge.Concatenate object at 0x7f39fe631a10>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f39fff13b50> and <keras.layers.advanced_activations.LeakyReLU object at 0x7f39fe838cd0>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f39fe6cca90> and <tf_implementation.scripts.models.ordinary_unet.BilinearUpSampling2D object at 0x7f39fe5890d0>).\n","WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f39fe8823d0> and <keras.layers.convolutional.Conv2D object at 0x7f39fe58d350>).\n"]},{"output_type":"stream","name":"stdout","text":["best test loss set to 0.013854780234396458\n"]}]},{"cell_type":"code","source":["ounet.model.save('final_model_pb/ounet.pb')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zcozXkWOTFU","executionInfo":{"status":"ok","timestamp":1647879043376,"user_tz":-210,"elapsed":54966,"user":{"displayName":"Fatemeh Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10033556401034287336"}},"outputId":"df404973-39c8-4a65-bef6-c9e43b6dc950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: final_model_pb/ounet.pb/assets\n"]}]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_saved_model('final_model_pb/ounet.pb') \n","tflite_model = converter.convert()\n","\n","# Save the model.\n","with open('final_model_pb/ounet.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhGTYHLDKzuW","executionInfo":{"status":"ok","timestamp":1647879077590,"user_tz":-210,"elapsed":34220,"user":{"displayName":"Fatemeh Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10033556401034287336"}},"outputId":"9613928e-d712-4119-afff-e7a31bc49cab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]}]},{"cell_type":"code","source":["# import tensorflow as tf\n","# import keras.backend as K\n","\n","# run_meta = tf.compat.v1.RunMetadata()\n","# with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n","#     K.set_session(sess)\n","#     net = OrdinaryUNet(config)\n","\n","#     opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()    \n","#     flops = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n","\n","#     opts = tf.compat.v1.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n","#     params = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n","\n","print(\"FLOPs {:,}\\nPARAMs {:,}\".format(flops.total_float_ops/1e6, params.total_parameters/1e6))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie4Q0OtW585W","executionInfo":{"status":"ok","timestamp":1643796875696,"user_tz":-210,"elapsed":6,"user":{"displayName":"Fateme Karimi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00001635288917064784"}},"outputId":"19cc7c93-16dd-45c8-c3bd-25488c8dfb5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FLOPs 42.81183\n","PARAMs 42.657689\n"]}]}]}