{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemehkarimii/LightDepth/blob/main/tf_implementation\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iweioMwSdIj",
        "cellView": "form",
        "outputId": "48e13da0-75fa-45a1-d55c-273d39e5d932"
      },
      "source": [
        "#@title mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cn5cEoTVMbl",
        "cellView": "form"
      },
      "source": [
        "#@title imports\n",
        "%%capture\n",
        "%cd /content/drive/MyDrive/DepthEstimation/\n",
        "%ls\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%load_ext tensorboard\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from glob import glob \n",
        "import numpy as np\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "# internal codes\n",
        "from torch_implementation.scripts.dataloaders import DepthDataLoader\n",
        "# from torch_implementation.scripts.models.ordinary_unet import OrdinaryUNet\n",
        "\n",
        "# from torch_implementation.scripts.utils import good\n",
        "# from torch_implementation.scripts.utils import update_train_filenames_file\n",
        "\n",
        "from torch_implementation.config import Config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OrdinaryUnet model\n",
        "class UpConv(torch.nn.Module):\n",
        "    def __init__(self,num_decode_filters,feature_map_num_filters):\n",
        "        super().__init__()\n",
        "        self.bilinear_up_sampling2d =  torch.nn.UpsamplingBilinear2d(\n",
        "            scale_factor=2)\n",
        "        self.conv1 = torch.nn.Conv2d(\n",
        "            feature_map_num_filters+num_decode_filters*2,\n",
        "            num_decode_filters,\n",
        "            3,\n",
        "            padding='same')\n",
        "        self.conv2 = torch.nn.Conv2d(\n",
        "            num_decode_filters,\n",
        "            num_decode_filters,\n",
        "            3,\n",
        "            padding='same')\n",
        "        self.leaky_relu = torch.nn.LeakyReLU(0.2)\n",
        "    \n",
        "    def forward_hook_callback(self,input,output):\n",
        "        self.feature_map = output.detach()\n",
        "\n",
        "    def forward(self,input):\n",
        "        upsampling_output = self.bilinear_up_sampling2d(input)\n",
        "        skipconnection_output = torch.concat(\n",
        "            [upsampling_output,\n",
        "             self.feature_map],\n",
        "            dim=1) #(NC1HW) (NC2HW) -> (NC12HW) \n",
        "        conv1_output = self.conv1(skipconnection_output)\n",
        "        leaky_relu1_output = self.leaky_relu(conv1_output)\n",
        "        conv2_output = self.conv2(leaky_relu1_output)\n",
        "        leaky_relu2_output = self.leaky_relu(conv2_output)\n",
        "        return leaky_relu2_output\n",
        "\n",
        "class UnetDecoder(torch.nn.Module):\n",
        "    def __init__(self,num_decode_filters,num_feature_map_filters):\n",
        "        super().__init__()\n",
        "        self.max_depth = 80.0\n",
        "        self.eps = 1e-5\n",
        "        self.conv1 = torch.nn.Conv2d(\n",
        "            num_decode_filters[0],\n",
        "            num_decode_filters[0],\n",
        "            kernel_size=1,\n",
        "            padding='same')\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.upconvlist = torch.nn.ModuleList()\n",
        "        for i,j in zip(num_decode_filters[1:],\n",
        "                       num_feature_map_filters):\n",
        "            self.upconvlist.append(UpConv(i,j))\n",
        "        self.conv2 = torch.nn.Conv2d(\n",
        "            num_decode_filters[-1],\n",
        "            1,\n",
        "            kernel_size=3,\n",
        "            padding='same')\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.upsample = torch.nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        \n",
        "    def forward(self,input):\n",
        "        relu_output = self.relu(input)\n",
        "        upconv = self.conv1(relu_output)\n",
        "        for layer in self.upconvlist:\n",
        "            upconv = layer(upconv)\n",
        "        conv2_output = self.conv2(upconv)\n",
        "        conv2_output_sigmoid = self.sigmoid(conv2_output)\n",
        "        upconv2_output = self.upsample(conv2_output_sigmoid)\n",
        "        output=upconv2_output*self.max_depth + self.eps\n",
        "        return upconv2_output\n",
        "\n",
        "class OrdinaryUnet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_decode_filters = 1664 # based on 3, 256, 512 (CHW) input\n",
        "        self.encoder = models.densenet169(pretrained=True).features\n",
        "        self.decoder = UnetDecoder(\n",
        "            [num_decode_filters,\n",
        "             num_decode_filters//2,\n",
        "             num_decode_filters//4,\n",
        "             num_decode_filters//8,\n",
        "             num_decode_filters//16],\n",
        "             [self.encoder.transition2[-2].out_channels,\n",
        "              self.encoder.transition1[-2].out_channels,\n",
        "              self.encoder.conv0.out_channels,\n",
        "              self.encoder.conv0.out_channels])\n",
        "        \n",
        "        # register forward hooks for skip connections\n",
        "        self.encoder.transition2.register_forward_hook(\n",
        "            self.decoder.upconvlist[0].forward_hook_callback) #keras' pool3_pool  32, 16, 256 (WHC)\n",
        "        self.encoder.transition1.register_forward_hook(\n",
        "            self.decoder.upconvlist[1].forward_hook_callback) #keras' pool2_pool  64, 32, 128\n",
        "        self.encoder.pool0.register_forward_hook(\n",
        "            self.decoder.upconvlist[2].forward_hook_callback) #keras' pool1  128, 64, 64\n",
        "        self.encoder.relu0.register_forward_hook(\n",
        "            self.decoder.upconvlist[3].forward_hook_callback) #keras' conv1/relu  256, 128, 64\n",
        "\n",
        "    def forward(self,input):\n",
        "        # input = self.quant(input)\n",
        "        encoder_output = self.encoder(input)\n",
        "        output = self.decoder(encoder_output)\n",
        "        # output = self.dequant(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "YinnpTVRy9-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ptflops import get_model_complexity_info\n",
        "import torch"
      ],
      "metadata": {
        "id": "9zQ4NwKvYgi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = OrdinaryUnet()\n",
        "model.eval()\n",
        "\n",
        "torchscript_model = torch.jit.script(model)\n",
        "\n",
        "# macs, params = get_model_complexity_info(model,(3,256,512), as_strings=True,\n",
        "#                                            print_per_layer_stat=True, verbose=True)"
      ],
      "metadata": {
        "id": "mxN9RSzsjsLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macs"
      ],
      "metadata": {
        "id": "b--pBDntYrfx",
        "outputId": "551d4224-89b0-4571-e9cb-ed11a755264e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'52.52 GMac'"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlfbD9fuYeEr",
        "outputId": "dfe63a67-52c3-41d1-c308-76bada84bc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.8.tar.gz (12 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (3.10.0.2)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.8-py3-none-any.whl size=11871 sha256=946a9eb9e90c47f3fba22dabb7ef7f665d331c4aedf552cb556ed63bfc98b8a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/ae/5f/74bef440471072ff2e39101cc9565460bfc17804f072bd7cff\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "id": "eycwp8hIYtIA",
        "outputId": "ff2471f3-bb95-4ea9-99a1-7768fc67a78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'42.66 M'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAA8CJ2MQpF9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}